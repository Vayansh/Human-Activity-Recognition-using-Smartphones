# Human-Activity-Recognition-using-Smartphones
## Motive 
To train a model that could detect Human Activity by simply using the inputs from their smartphones. I believe such a model can be of great use in varieties of fields from fitness applications where it can use this model and detect calorie consumption from daily activities to the Military for precise aiming. 

## More on Dataset
I used the dataset from Kaggle. 
[Link to Dataset](https://www.kaggle.com/datasets/uciml/human-activity-recognition-with-smartphones)

### Explanation of Dataset from Kaggle
The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKINGUPSTAIRS, WALKINGDOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers were selected for generating the training data and 30% for the test data.

## How do I tackle this Question?
I applied an artificial neural network (ANN) model and got a training accuracy of about 99% and validation accuracy of about 95% and a predicted accuracy of about 93%.

## Some plots

Loss over Epoches
![image](https://user-images.githubusercontent.com/92180055/190886961-fa70e8ff-00fc-4dc3-b6fa-0063b27fb4f9.png)

Accuracy over Epoches
![image](https://user-images.githubusercontent.com/92180055/190886968-895edbe0-ba20-4dbf-b67f-aee0885b9231.png)


